{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71197b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading serialized graph\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import rdflib\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "serialized_path = \"../Dataset/graph.pkl\"\n",
    "with open(serialized_path, 'rb') as f:\n",
    "    print(\"Loading serialized graph\")\n",
    "    graph = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60880fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'http://www.wikidata.org/entity/Q457180'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://www.wikidata.org/entity/Q457180\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m ent2lbl \u001b[38;5;241m=\u001b[39m {ent: \u001b[38;5;28mstr\u001b[39m(lbl) \u001b[38;5;28;01mfor\u001b[39;00m ent, lbl \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39msubject_objects(RDFS\u001b[38;5;241m.\u001b[39mlabel)}\n\u001b[1;32m----> 6\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43ment2lbl\u001b[49m\u001b[43m[\u001b[49m\u001b[43muri\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ans)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'http://www.wikidata.org/entity/Q457180'"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "RDFS = rdflib.namespace.RDFS\n",
    "uri = 'http://www.wikidata.org/entity/Q457180'\n",
    "\n",
    "ent2lbl = {ent: str(lbl) for ent, lbl in graph.subject_objects(RDFS.label)}\n",
    "ans = ent2lbl[uri]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_template = '''\n",
    "#             PREFIX ddis: <http://ddis.ch/atai/>\n",
    "#             PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "#             PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "#             PREFIX schema: <http://schema.org/>\n",
    "#             PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            \n",
    "#             SELECT ?movie ?movieLabel ?predicateLabel ?object ?objectLabel WHERE {{\n",
    "#                 # Find the movie entity based on an exact match for the label\n",
    "#                 ?movie rdfs:label \"{0}\"@en .\n",
    "                \n",
    "#                 # Retrieve all predicates and objects related to the movie entity\n",
    "#                 ?movie ?predicate ?object .\n",
    "\n",
    "#                 FILTER(?predicate IN (\n",
    "#                       wdt:P31,   # instance of\n",
    "#                       wdt:P57,   # director\n",
    "#                       wdt:P162,  # producer\n",
    "#                       wdt:P364,  # original language\n",
    "#                       wdt:P272,  # production company\n",
    "#                       wdt:P58,   # screenwriter\n",
    "#                       wdt:P166,  # award received\n",
    "#                       wdt:P2047, # duration\n",
    "#                       wdt:P577 # release date\n",
    "#                   ))\n",
    "\n",
    "#                 # Optionally retrieve labels for predicates and objects\n",
    "#                 OPTIONAL {{ ?predicate rdfs:label ?predicateLabel . FILTER(LANG(?predicateLabel) = \"en\") }}\n",
    "#                 OPTIONAL {{ ?object rdfs:label ?objectLabel . FILTER(LANG(?objectLabel) = \"en\") }}\n",
    "#                 OPTIONAL {{ ?movie rdfs:label ?movieLabel . FILTER(LANG(?movieLabel) = \"en\") }}\n",
    "#             }}\n",
    "#             ORDER BY ?movie\n",
    "#         '''\n",
    "\n",
    "# movie_name = \"The Godfather\"\n",
    "# query = query_template.format(movie_name)\n",
    "\n",
    "# result = graph.query(query)\n",
    "# res = [str(row) for row in result]\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Query All Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total genres found: 357\n",
      "['LGBT-related film', 'romance film', 'comedy film', 'Western film', 'parody film', 'drama', 'action film', 'thriller film', 'kung fu film', 'war film', 'documentary film', 'gangster film', 'historical film', 'biographical film', 'crime thriller', 'film based on books', 'spy film', 'teen film', 'rape and revenge film', 'independent film', 'crime film', 'comedy-drama', 'horror film', 'fantasy film', 'historical drama', 'family film', 'Christmas film', 'romantic comedy', \"children's film\", 'black comedy film', 'musical film', 'road movie', 'neo-noir', 'martial arts film', 'girls with guns', 'erotic thriller', 'coming-of-age story', 'hood film', 'heist film', 'monster film', 'film based on literature', 'slasher film', 'buddy cop film', 'buddy film', 'police film', 'political thriller', 'suspense', 'adventure film', 'science fiction film', 'concert film', 'trial film', 'splatter film', 'musical comedy', 'cannibal film', 'found footage', 'psychological thriller', 'sex comedy', 'mystery film', 'dystopian film', 'animated film', 'speculative fiction film', 'anthology film', 'political drama', 'film noir', 'art film', 'rockumentary', 'social problem film', 'sport film', 'post-apocalyptic film', 'zombie film', 'action-adventure film', 'computer animation', 'detective film', 'flashback film', 'action thriller', 'B movie', 'female buddy film', 'anti-war film', 'pirate film', 'swashbuckler film', 'treasure hunt film', 'film adaptation', 'action comedy film', 'docudrama', 'caper story', 'vigilante film', 'mockumentary', 'disaster film', 'prison film', 'spaghetti western', 'samurai cinema', 'comedy of remarriage', 'vampire film', 'comedy horror', 'comic science fiction', 'slice of life', 'film based on a novel', 'zombie comedy', 'silent film', 'blaxploitation', 'comedy thriller', 'melodrama', 'legal drama', 'circus film', 'love triangle romance', 'farce', 'thriller', 'epic film', 'Bollywood', 'crime-comedy film', 'mockbuster', 'steampunk film', 'erotic film', 'comedy of manners', 'superhero film', 'slapstick', 'body horror film', 'partisan film', 'drama television series', 'survival film', 'Peplum film genre', 'costume drama', 'alien invasion', 'screwball comedy film', 'knight film', 'cyberpunk', 'propaganda film', 'psychological drama film', 'surf film', 'time-travel film', 'psychological horror', 'satirical film', 'tragicomedy', 'anime film', 'nature documentary', 'exploitation film', 'religious film', 'gothic horror film', 'poliziotteschi', 'miniseries', 'battle', 'comedy', 'Revisionist Western', 'cinematic fairy tale', 'sexploitation film', 'fiction film', 'LGBTI+ related TV series', 'soundtrack', 'Western', 'adventure anime and manga', 'submarine film', 'pornographic film', 'speculative fiction', 'puppet film', 'detective fiction', 'magic realist film', 'fictional crossover', 'Kaiju', 'techno-thriller', 'alternate history film', 'dance film', 'country music', 'stoner film', 'auteur film', 'romance novel', 'epic literature', 'DR', 'horror fiction', 'black comedy', 'coming-of-age film', 'Heimatfilm', 'parody', 'wuxia', 'stand-up comedy', 'Mumblecore', 'supernatural film', 'historical fiction', 'stop-motion animated film', 'supernatural fiction', 'medical drama', 'thriller anime', 'Redsploitation', 'mecha', 'drama anime and manga', 'fantasy anime and manga', 'outlaw biker film', 'backwoods film', 'science fiction comic', 'political satire', 'talk show', 'dark fantasy', 'Eastern', 'romantic drama', 'heroic bloodshed', 'transgender film', 'hyperlink cinema', 'docufiction', 'pop music', 'experimental film', 'mysticism', 'pritcha', 'New Queer Cinema', 'Love Story', 'police procedural', 'reality', 'science fiction', 'Yue Chinese', 'Mandarin Chinese', 'social comedy', 'dystopia', 'science fiction action film', 'culture clash comedy', 'Masala', 'Holocaust in the movies', 'filmi music', 'financial thriller', 'natural horror film', 'fiction', 'adventure fiction', 'tragedy', 'soul music', 'yaoi', 'erotica', 'comedy anime and manga', 'essay film', 'biography', 'play', 'supernatural horror film', 'novel', 'political film', 'giallo', 'paranormal phenomenon', 'superhero', 'military science fiction', 'teen drama', 'fantasy', 'tokusatsu', 'Avogadro constant', 'puppetoon', 'stop-motion', 'Slavic fantasy', 'romance', 'beach party film', 'punk rock', \"Commedia all'italiana\", 'romance anime and manga', 'post-apocalyptic fiction', 'Jidaigeki', 'historical novel', 'fear', 'pseudo-documentary', 'parable', 'werewolf film', 'Biblical genre', 'gore', 'Computer screen film', 'autobiographical film', 'ghost film', 'biopunk', 'nunsploitation', 'nonlinear narrative', 'apocalyptic fiction', 'Acid Western', 'world music', 'computer-animated film', 'jukebox musical', 'sitcom', 'New German Cinema', 'science fiction television series', 'Huis clos', 'prequel film', 'Tamil cinema', 'Dieselpunk', 'romantic thriller', 'yakuza film', 'intersex film', 'animated film with LGBT character(s)', \"children's literature\", 'adventure', 'psychological novel', 'documentary', 'women in prison film', 'rhythm and blues', 'film score', 'rock and roll', 'coming of age', 'family drama', 'horror anime and manga', 'mystery fiction', 'Z movie', 'Christian fiction', 'prequel', 'anime', 'action anime and manga', 'live-action/animated film', 'mystery play', 'hard rock', 'school anime and manga', 'kabuki', 'rock music', 'tech noir', 'legal thriller', 'psycho-biddy', 'historical television series', 'adventure television series', 'television series based on a novel', 'film remake', 'clay animation film', 'science fiction anime', 'autobiography', 'hip hop music', 'magical girl', 'cinematography', 'medical thriller', 'philosophical fiction', 'crime novel', 'bossa nova', 'locked room mystery', 'surrealist cinema', 'psychedelic film', 'fantasy television', 'Nazi exploitation', 'apocalyptic film', 'sword and sorcery', 'comedic television series', 'burlesque', 'time travel', 'comic book', 'live action', 'image film', 'robinsonade', 'fantastique', 'cult film', 'image', 'noir fiction', 'Japanese horror', 'psychological experiment', 'surreal humour', 'science fantasy', 'musical', 'gambling film', 'boxing', 'traditionally animated film', 'science fiction anime and manga', 'urban fantasy', 'religious satire', 'space opera', 'steampunk fiction', 'comedy of error', 'alternative rock', 'crime', 'space adventure film', 'Space Western', 'high fantasy', 'wuxia film', 'ecchi', 'television comedy']\n"
     ]
    }
   ],
   "source": [
    "# Define the SPARQL query\n",
    "# Define the SPARQL query to select all movie genres from the knowledge graph\n",
    "query = '''\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?genreLabel WHERE {\n",
    "  ?movie wdt:P31 wd:Q11424 .\n",
    "  ?movie wdt:P136 ?genre .\n",
    "  ?genre rdfs:label ?genreLabel .\n",
    "  FILTER(LANG(?genreLabel) = \"en\")\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "# Execute the query\n",
    "result = graph.query(query)\n",
    "\n",
    "# Extract movie genres into a list\n",
    "genres = [str(row.genreLabel) for row in result]\n",
    "print(\"Total genres found:\", len(genres))\n",
    "print(genres) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Dataset/MovieTitles\", 'wb') as f:\n",
    "#     pickle.dump(movie_names, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Query all person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the SPARQL query for extracting persons\n",
    "# query = '''\n",
    "# PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "# PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "# PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "# SELECT ?personLabel WHERE {\n",
    "#   ?person wdt:P31 wd:Q5 .  # Q5 represents humans on Wikidata\n",
    "#   ?person rdfs:label ?personLabel .\n",
    "#   FILTER(LANG(?personLabel) = \"en\")\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# # Execute the query and extract person names\n",
    "# result = graph.query(query)\n",
    "# person_names = [str(row.personLabel) for row in result]\n",
    "# print(\"Total persons found:\", len(person_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Dataset/MovieTitles\", 'wb') as f:\n",
    "#     pickle.dump(person_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Read movie titles from the text file and save as a pickle file\n",
    "with open(\"../Dataset/MovieTitles.txt\", 'r') as txt_file:\n",
    "    # Read the content of the text file\n",
    "    content = txt_file.read()\n",
    "    \n",
    "    # Convert the string representation of a list into a Python list\n",
    "    movie_titles = eval(content)\n",
    "\n",
    "# Save the movie titles as a pickle file\n",
    "with open(\"../Dataset/MovieTitles.pickle\", 'wb') as pickle_file:\n",
    "    pickle.dump(movie_titles, pickle_file)\n",
    "\n",
    "# Load movie titles from the pickle file\n",
    "with open(\"../Dataset/MovieTitles.pickle\", 'rb') as pickle_file:\n",
    "    movie_titles = pickle.load(pickle_file)\n",
    "\n",
    "# Convert movie titles to a list (in case it is not already)\n",
    "movie_titles = list(movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    # Existing templates\n",
    "    \"When was {MOVIE} released?\",\n",
    "    \"Who directed the movie {MOVIE}?\",\n",
    "    \"Who directed {MOVIE}?\",\n",
    "    \"Who is the director of {MOVIE}?\",\n",
    "    \"Did James Cameron direct {MOVIE}?\",\n",
    "    \"Does James Cameron direct {MOVIE}?\",\n",
    "    \"Did {MOVIE} have the same director as {MOVIE}?\",\n",
    "    \"Is {MOVIE} set in the French Renaissance period?\",\n",
    "    \"Is {MOVIE} directed by Stanley Kubrick?\",\n",
    "    \"Is {MOVIE} a sequel?\",\n",
    "    \"Recommend movies similar to {MOVIE} and {MOVIE}.\",\n",
    "    \"Recommend movies like {MOVIE}.\",\n",
    "    \"Recommend movies like {MOVIE}, {MOVIE}, and {MOVIE}.\",\n",
    "    \"Given that I like {MOVIE}, {MOVIE}, and {MOVIE}, recommend some movies.\",\n",
    "\n",
    "    # Additional templates\n",
    "    \"What is the release date of {MOVIE}?\",\n",
    "    \"What was {MOVIE} released?\",\n",
    "    \"Who played the lead role in {MOVIE}?\",\n",
    "    \"Did {MOVIE} win any Academy Awards?\",\n",
    "    \"What is the IMDb rating of {MOVIE}?\",\n",
    "    \"What is the genre of {MOVIE}?\",\n",
    "    \"Who wrote the screenplay for {MOVIE}?\",\n",
    "    \"Who is the screenwriter of {MOVIE}?\",\n",
    "    \"What is the box office collection of {MOVIE}?\",\n",
    "    \"Who was the cinematographer for {MOVIE}?\",\n",
    "    \"What is the runtime of {MOVIE}?\",\n",
    "    \"Did {MOVIE} feature any award-winning performances?\",\n",
    "    \"Who composed the music for {MOVIE}?\",\n",
    "    \"What is the main theme of {MOVIE}?\",\n",
    "    \"What awards did {MOVIE} receive?\",\n",
    "    \"What is the production company of {MOVIE}?\",\n",
    "    \"What languages does {MOVIE} support?\",\n",
    "    \"Is {MOVIE} based on a true story?\",\n",
    "    \"Who is the writer of {MOVIE}?\",\n",
    "    \"Is {MOVIE} set in a specific historical period?\",\n",
    "    \"Who is the executive producer of {MOVIE}?\",\n",
    "    \"I loved {MOVIE} and {MOVIE}. What else should I watch?\",\n",
    "    \"What movies will I like if I like {MOVIE}?\",\n",
    "    \"Can you recommend movies similar to {MOVIE}?\",\n",
    "    \"Given that I like {MOVIE}, {MOVIE}, and {MOVIE}, recommend some movies.\",\n",
    "    \"Suggest films with similar vibes to {MOVIE}.\",\n",
    "    \"Recommend movies with time travel themes, for example {MOVIE}.\",\n",
    "    \"Suggest movies related to {MOVIE}.\",\n",
    "    \"What movies are like {MOVIE}?\",\n",
    "    \"Any recommendations for animated movies like {MOVIE}?\",\n",
    "    \"Recommend movies that are similar to {MOVIE}.\",\n",
    "    \"What movies should I watch if I enjoyed {MOVIE}?\",\n",
    "    \"Recommend animated movies to watch if I liked {MOVIE}.\",\n",
    "    # Factual questions converted into templates\n",
    "    \"When was {MOVIE} released?\",\n",
    "    \"Who is the director of {MOVIE}?\",\n",
    "    \"Who directed {MOVIE}?\",\n",
    "    \"What is the MPAA film rating of {MOVIE}?\",\n",
    "    \"What is the genre of {MOVIE}?\",\n",
    "    \"What is the box office of {MOVIE}?\",\n",
    "    \"Can you tell me the publication date of {MOVIE}?\",\n",
    "    \"Who is the executive producer of {MOVIE}?\",\n",
    "    \"Which director is known for {MOVIE}?\",\n",
    "    \"Is {MOVIE} set in the French Renaissance period?\",\n",
    "    # Recommendation questions converted into templates\n",
    "    \"Recommend movies similar to {MOVIE} and {MOVIE}.\",\n",
    "    \"Given that I like {MOVIE}, {MOVIE}, and {MOVIE}, can you recommend some movies?\",\n",
    "    \"Recommend movies like {MOVIE}, {MOVIE}, and {MOVIE}.\",\n",
    "    \"What movies will I like if I like {MOVIE}?\",\n",
    "    \"Give me movies like {MOVIE}.\",\n",
    "]\n",
    "\n",
    "additional_templates = [\n",
    "    # General queries\n",
    "    \"Tell me about {MOVIE}.\",\n",
    "    \"What is {MOVIE} about?\",\n",
    "    \"Can you provide a summary of {MOVIE}?\",\n",
    "    \"Is {MOVIE} worth watching?\",\n",
    "    \"What are some reviews of {MOVIE}?\",\n",
    "    # Awards and nominations\n",
    "    \"How many awards has {MOVIE} won?\",\n",
    "    \"Was {MOVIE} nominated for any Oscars?\",\n",
    "    \"Did {MOVIE} win any Golden Globe awards?\",\n",
    "    # Cast and crew\n",
    "    \"Who starred in {MOVIE}?\",\n",
    "    \"Who are the main actors in {MOVIE}?\",\n",
    "    \"List the cast of {MOVIE}.\",\n",
    "    \"Who produced {MOVIE}?\",\n",
    "    # Sequels and series\n",
    "    \"Is {MOVIE} part of a series?\",\n",
    "    \"What is the sequel to {MOVIE}?\",\n",
    "    \"What movies are prequels to {MOVIE}?\",\n",
    "    # Release information\n",
    "    \"When did {MOVIE} come out?\",\n",
    "    \"What year was {MOVIE} released?\",\n",
    "    # Genre and style\n",
    "    \"Is {MOVIE} a comedy or a drama?\",\n",
    "    \"What style of film is {MOVIE}?\",\n",
    "    \"Is {MOVIE} a horror movie?\",\n",
    "    # Recommendations based on mood or theme\n",
    "    \"I'm looking for movies like {MOVIE}. Any suggestions?\",\n",
    "    \"What should I watch if I enjoyed {MOVIE}?\",\n",
    "    \"Movies similar in theme to {MOVIE}?\",\n",
    "    # Box office and ratings\n",
    "    \"How successful was {MOVIE} at the box office?\",\n",
    "    \"What ratings did {MOVIE} receive?\",\n",
    "    \"Is {MOVIE} critically acclaimed?\",\n",
    "    # Availability\n",
    "    \"Where can I watch {MOVIE}?\",\n",
    "    \"Is {MOVIE} available on Netflix?\",\n",
    "    # Personal opinions\n",
    "    \"Do you think {MOVIE} is a good film?\",\n",
    "    \"Would you recommend {MOVIE}?\",\n",
    "    # Comparisons\n",
    "    \"Which is better, {MOVIE} or {MOVIE}?\",\n",
    "    \"How does {MOVIE} compare to {MOVIE}?\",\n",
    "    # Behind the scenes\n",
    "    \"Are there any interesting facts about {MOVIE}?\",\n",
    "    \"Tell me some trivia about {MOVIE}.\",\n",
    "    # Soundtracks\n",
    "    \"Who composed the soundtrack for {MOVIE}?\",\n",
    "    \"Is the music in {MOVIE} noteworthy?\",\n",
    "    # Technical details\n",
    "    \"What camera was used to film {MOVIE}?\",\n",
    "    \"Was {MOVIE} shot in digital or on film?\",\n",
    "    # Language and subtitles\n",
    "    \"Is {MOVIE} in English?\",\n",
    "    \"Does {MOVIE} have subtitles?\",\n",
    "    # Cultural impact\n",
    "    \"How did {MOVIE} influence cinema?\",\n",
    "    \"What is the cultural significance of {MOVIE}?\",\n",
    "    # Audience\n",
    "    \"Is {MOVIE} suitable for children?\",\n",
    "    \"Can kids watch {MOVIE}?\",\n",
    "    # Plot specifics\n",
    "    \"Does {MOVIE} have a happy ending?\",\n",
    "    \"What happens at the end of {MOVIE}?\",\n",
    "    # Release formats\n",
    "    \"Is there a 3D version of {MOVIE}?\",\n",
    "    \"Was {MOVIE} released in IMAX?\",\n",
    "    # Miscellaneous\n",
    "    \"Did {MOVIE} face any controversies?\",\n",
    "    \"What are the themes explored in {MOVIE}?\",\n",
    "    \"Is {MOVIE} based on a book?\",\n",
    "    \"Who wrote the original story for {MOVIE}?\",\n",
    "    \"Are there any spin-offs from {MOVIE}?\",\n",
    "    \"What inspired the creation of {MOVIE}?\",\n",
    "]\n",
    "\n",
    "templates.extend(additional_templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "\n",
    "DATASET_FILE = \"movie_title_dataset.json\"\n",
    "\n",
    "def process_template(template, selected_movies):\n",
    "    # Use regex to split the template by {MOVIE} placeholders\n",
    "    pattern = re.compile(r'(\\{MOVIE\\})')\n",
    "    parts = pattern.split(template)\n",
    "    sentence_words = []\n",
    "    labels = []\n",
    "    movie_idx = 0\n",
    "    for part in parts:\n",
    "        if part == \"{MOVIE}\":\n",
    "            # Replace with movie title and label it\n",
    "            movie = selected_movies[movie_idx]\n",
    "            movie_idx += 1\n",
    "            movie_words = movie.split()\n",
    "            sentence_words.extend(movie_words)\n",
    "            labels.extend([\"B-MOVIE\"] + [\"I-MOVIE\"] * (len(movie_words) - 1))\n",
    "        else:\n",
    "            # Split the non-placeholder parts into words and label as 'O'\n",
    "            words = part.split()\n",
    "            sentence_words.extend(words)\n",
    "            labels.extend([\"O\"] * len(words))\n",
    "    return sentence_words, labels\n",
    "\n",
    "def generate_dataset(movie_titles, templates, size=60000, output_file=DATASET_FILE):\n",
    "    dataset = []\n",
    "    SENTENCE_LEN_THRESHOLD = 100\n",
    "\n",
    "    # Step 1: Ensure each movie title is included at least once\n",
    "    for movie in movie_titles:\n",
    "        # Choose a template with at least one {MOVIE} placeholder\n",
    "        valid_templates = [t for t in templates if \"{MOVIE}\" in t]\n",
    "        template = random.choice(valid_templates)\n",
    "\n",
    "        # Count the number of {MOVIE} placeholders\n",
    "        movie_placeholders = template.count(\"{MOVIE}\")\n",
    "\n",
    "        # Select movies to replace placeholders\n",
    "        selected_movies = [movie]\n",
    "\n",
    "        # If more placeholders, fill with random movies excluding the current one\n",
    "        if movie_placeholders > 1:\n",
    "            remaining_movies = list(set(movie_titles) - set([movie]))\n",
    "            additional_movies = random.sample(remaining_movies, min(movie_placeholders - 1, len(remaining_movies)))\n",
    "            selected_movies.extend(additional_movies)\n",
    "\n",
    "        # Process the template to get words and labels\n",
    "        sentence_words, labels = process_template(template, selected_movies)\n",
    "\n",
    "        if len(sentence_words) > SENTENCE_LEN_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        dataset.append({\"sentence\": sentence_words, \"labels\": labels})\n",
    "\n",
    "    # Step 2: Generate additional sentences to reach the desired size\n",
    "    while len(dataset) < size:\n",
    "        template = random.choice(templates)\n",
    "        movie_placeholders = template.count(\"{MOVIE}\")\n",
    "\n",
    "        # Randomly select movie titles for each placeholder\n",
    "        if movie_placeholders > 0:\n",
    "            selected_movies = random.sample(movie_titles, min(movie_placeholders, len(movie_titles)))\n",
    "        else:\n",
    "            selected_movies = []\n",
    "\n",
    "        # Process the template to get words and labels\n",
    "        sentence_words, labels = process_template(template, selected_movies)\n",
    "\n",
    "        if len(sentence_words) > SENTENCE_LEN_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        dataset.append({\"sentence\": sentence_words, \"labels\": labels})\n",
    "\n",
    "    # Save dataset as JSON Lines\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for example in dataset:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "    # Convert the data to CSV for visual inspection\n",
    "    with open(\"movie_title_dataset.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"sentence\", \"labels\"])\n",
    "        for example in dataset:\n",
    "            # Convert lists to space-separated strings\n",
    "            sentence_str = ' '.join(example['sentence'])\n",
    "            labels_str = ' '.join(example['labels'])\n",
    "            writer.writerow([sentence_str, labels_str])\n",
    "\n",
    "    print(f\"Dataset saved to {output_file} and 'movie_title_dataset.csv'\")\n",
    "\n",
    "# Generate the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63882378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA = generate_dataset(movie_titles, templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d591d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from JSON Lines file\n",
    "dataset = load_dataset('json', data_files=DATASET_FILE, split='train')\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_testvalid = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "train_dataset = train_testvalid['train']\n",
    "eval_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "tokenize the sentences in the dataset using the `BertTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "label_list = [\"O\", \"B-MOVIE\", \"I-MOVIE\"]\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_map[label[word_idx]])\n",
    "            else:\n",
    "                # Set the label for sub-tokens to -100 to ignore during loss computation\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10400004",
   "metadata": {},
   "source": [
    "Tokenization to all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85527751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenization to all datasets\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Tune the BERT-base-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U accelerate\n",
    "# %pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should display your GPU name, e.g., 'NVIDIA GeForce RTX 4060'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "label_list = [\"O\", \"B-MOVIE\", \"I-MOVIE\"]\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [[label_list[pred] for pred, lab in zip(prediction, label) if lab != -100]\n",
    "                        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_list))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=300,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Define the compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = [\n",
    "        [label_list[l] for l in label if l != -100]\n",
    "        for label in labels\n",
    "    ]\n",
    "    true_predictions = [\n",
    "        [label_list[pred] for pred, lab in zip(prediction, label) if lab != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693f20c",
   "metadata": {},
   "source": [
    "## Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54405e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_BERT_base_uncased\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_BERT_base_uncased\")\n",
    "\n",
    "print(\"Model and tokenizer saved to './fine_tuned_BERT_base_uncased'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_BERT_base_uncased\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./fine_tuned_BERT_base_uncased\")\n",
    "\n",
    "# Create the pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Example inference\n",
    "sentences = [\n",
    "    \"Is Wildcats directed by Stanley Kubrick?\",\n",
    "    \"Who played the lead role in Avatar\",\n",
    "    \"Who directed Night Across the Street\",\n",
    "    \"When was The Godfather released?\",\n",
    "    \"When was 'The Godfather' released?\",\n",
    "    \"Who is the screenwriter of The Masked Gang: Cyprus?\",\n",
    "    \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\",\n",
    "]\n",
    "\n",
    "sentences_1 = [\n",
    "        \"Did Christopher Nolan direct Inception?\",\n",
    "    \"Is GoldenEye 007 a James Bond movie?\",\n",
    "\"Is Following a black and white film?\",\n",
    "\"Does the lord of the Rings Trilogy consist of three movies?\",\n",
    "\"Does First Man depict the life of Neil Armstrong?\",\n",
    "\"Is La Princesse de Clèves set in the French Renaissance period?\",\n",
    "\"Is 2001: A Space Odyssey directed by Stanley Kubrick?\",\n",
    "\"Is Devil in the Flesh 2 a sequel?\",\n",
    "\"Did James Cameron direct Titanic?\",\n",
    "]\n",
    "\n",
    "for s in sentences_1:\n",
    "    ner_results = ner_pipeline(s)\n",
    "\n",
    "    print(f\"\\nSentence: \\\"{s}\\\"\")\n",
    "    if ner_results:\n",
    "        for entity in ner_results:\n",
    "            label = entity[\"entity_group\"]\n",
    "            word = entity[\"word\"]\n",
    "            score = entity[\"score\"]\n",
    "            if label in ('LABEL_1', 'LABEL_2'):\n",
    "                print(f\"  - Entity: '{word}', Label: '{label}', Confidence: {score:.2f}\")\n",
    "    else:\n",
    "        print(\"No entities found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model\n",
    "ner_pipeline = pipeline(\"ner\", model=\"./Tuned_BERT_NER_movie-60000\", tokenizer=\"./Tuned_BERT_NER_movie-60000\", aggregation_strategy=\"simple\", device=\"cuda\")\n",
    "\n",
    "# Example inference\n",
    "sentences = [\n",
    "    \"Let's talk about Avatar.\",\n",
    "    \"When was The Godfather released?\",\n",
    "    \"When was vampire assassin released?\",\n",
    "    \"Who is the screenwriter of The Masked Gang: Cyprus?\",\n",
    "    \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\",\n",
    "]\n",
    "\n",
    "sentences_1 = [\n",
    "        \"Did Christopher Nolan direct Inception?\",\n",
    "    \"Is GoldenEye 007 a James Bond movie?\",\n",
    "\"Is Following a black and white film?\",\n",
    "\"Does the lord of the Rings Trilogy consist of three movies?\",\n",
    "\"Does First Man depict the life of Neil Armstrong?\",\n",
    "\"Is La Princesse de Clèves set in the French Renaissance period?\",\n",
    "\"Is 2001: A Space Odyssey directed by Stanley Kubrick?\",\n",
    "\"Is Devil in the Flesh 2 a sequel?\",\n",
    "\"Did James Cameron direct Titanic?\",\n",
    "]\n",
    "\n",
    "recommendation_sentence = [\n",
    "    \"Given that I like Inception, The Godfather can you recommend me some movies\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    ner_results = ner_pipeline(s)\n",
    "\n",
    "    print(f\"\\nSentence: \\\"{s}\\\"\")\n",
    "    if ner_results:\n",
    "        for entity in ner_results:\n",
    "            label = entity[\"entity_group\"]\n",
    "            word = entity[\"word\"]\n",
    "            score = entity[\"score\"]\n",
    "            if label in ('LABEL_1', 'LABEL_2'):\n",
    "                print(f\"  - Entity: '{word}', Label: '{label}', Confidence: {score:.2f}\")\n",
    "    else:\n",
    "        print(\"No entities found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATAIChatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
